<!-- build time:Sat Jun 13 2020 14:45:51 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>HDFS读写原理 | junthy&#39;s blog</title><meta name="description" content="Hadoop 是什么Hadoop 是一个开源的大数据框架同时也是一个分布式计算的解决方案。Hadoop = HDFS （分布式文件系统）+MapReduce（分布式计算） HDFS HDFS 概念数据块NameNodeDataNode 数据块：数据块是一个抽象的块，而不是整个文件。默认大小是64Mb，一般设置为128Mb，备份x3数据块的大小可以随着磁盘传输速率的提升而得到增加。HDFS的块比磁"><meta name="keywords" content="HDFS"><meta property="og:type" content="article"><meta property="og:title" content="HDFS读写原理"><meta property="og:url" content="http://81.68.66.74/2019/08/25/Hadoop-HDFS读写原理/index.html"><meta property="og:site_name" content="Junthy&#39;s Blog"><meta property="og:description" content="Hadoop 是什么Hadoop 是一个开源的大数据框架同时也是一个分布式计算的解决方案。Hadoop = HDFS （分布式文件系统）+MapReduce（分布式计算） HDFS HDFS 概念数据块NameNodeDataNode 数据块：数据块是一个抽象的块，而不是整个文件。默认大小是64Mb，一般设置为128Mb，备份x3数据块的大小可以随着磁盘传输速率的提升而得到增加。HDFS的块比磁"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://81.68.66.74/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E6%85%95%E8%AF%BE%EF%BC%89.png"><meta property="og:image" content="http://81.68.66.74/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E5%B7%B2%E7%BB%8F%E8%AF%BB%E5%8F%96%E5%AE%8C%E6%AF%95%EF%BC%89.png"><meta property="og:image" content="http://81.68.66.74/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E8%AF%A6%E7%BB%86%EF%BC%89.png"><meta property="og:image" content="http://81.68.66.74/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E5%86%99%E6%B5%81%E7%A8%8B.png"><meta property="og:image" content="http://81.68.66.74/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E5%86%99%E6%B5%81%E7%A8%8B%EF%BC%88%E8%AF%A6%E7%BB%86%EF%BC%89.png"><meta property="og:updated_time" content="2020-06-13T02:26:03.393Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="HDFS读写原理"><meta name="twitter:description" content="Hadoop 是什么Hadoop 是一个开源的大数据框架同时也是一个分布式计算的解决方案。Hadoop = HDFS （分布式文件系统）+MapReduce（分布式计算） HDFS HDFS 概念数据块NameNodeDataNode 数据块：数据块是一个抽象的块，而不是整个文件。默认大小是64Mb，一般设置为128Mb，备份x3数据块的大小可以随着磁盘传输速率的提升而得到增加。HDFS的块比磁"><meta name="twitter:image" content="http://81.68.66.74/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E6%85%95%E8%AF%BE%EF%BC%89.png"><link rel="canonical" href="http://81.68.66.74/2019/08/25/Hadoop-HDFS读写原理/index.html"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.css" rel="stylesheet"><link rel="alternate" href="/atom.xml" title="Junthy's Blog" type="application/atom+xml"></head><head><script type="text/javascript" src="/js/clicklove.js"></script></head><body class="main-center theme-blue# 主题颜色 theme-black theme-blue theme-green theme-purple" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/juntao-hu" target="_blank" rel="external nofollow noopener noreferrer"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">junthy</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">Big Data Engineer</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> 深圳，中国</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="搜索"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech=""> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">首页</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">归档</span></a></li><li class="menu-item menu-item-categories"><a href="/categories"><i class="icon icon-folder"></i> <span class="menu-title">分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">标签</span></a></li><li class="menu-item menu-item-repository"><a href="/repository"><i class="icon icon-project"></i> <span class="menu-title">项目</span></a></li><li class="menu-item menu-item-books"><a href="/books"><i class="icon icon-book-fill"></i> <span class="menu-title">书单</span></a></li><li class="menu-item menu-item-links"><a href="/links"><i class="icon icon-friendship"></i> <span class="menu-title">友链</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">关于</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/juntao-hu" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="http://weibo.com/cofess" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">公告</h3><div class="widget-body"><div id="board"><div class="content"><p>欢迎交流与分享经验!</p></div></div></div></div><div class="widget"><h3 class="widget-title">分类</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/面试/">面试</a><span class="category-list-count">2</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签</h3><div class="widget-body"><ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArrayList/">ArrayList</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Arrays/">Arrays</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HDFS/">HDFS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java链表/">Java链表</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark原理/">Spark原理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/二分查找/">二分查找</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/剑指offer/">剑指offer</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/基本排序算法/">基本排序算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/读书笔记/">读书笔记</a><span class="tag-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">归档</h3><div class="widget-body"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a><span class="archive-list-count">2</span></li></ul></div></div><div class="widget"><h3 class="widget-title">最新文章</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/LeetCode/">LeetCode</a></p><p class="item-title"><a href="/2019/10/22/LeetCode-74-search-a-2d-matrix/" class="title">LeetCode 74. 搜索二维矩阵</a></p><p class="item-date"><time datetime="2019-10-22T00:00:00.000Z" itemprop="datePublished">2019/10/22</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/LeetCode/">LeetCode</a></p><p class="item-title"><a href="/2019/10/22/LeetCode-34-find-first-and-last-position-of-element-in-sorted-array/" class="title">LeetCode 34. 在排序数组中查找元素的第一个和最后一个位置</a></p><p class="item-date"><time datetime="2019-10-22T00:00:00.000Z" itemprop="datePublished">2019/10/22</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/LeetCode/">LeetCode</a></p><p class="item-title"><a href="/2019/10/21/LeetCode-35-search-insert-position/" class="title">LeetCode 35. 搜索插入位置</a></p><p class="item-date"><time datetime="2019-10-21T00:00:00.000Z" itemprop="datePublished">2019/10/21</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/LeetCode/">LeetCode</a></p><p class="item-title"><a href="/2019/10/21/LeetCode-69-sqrtx/" class="title">LeetCode 69. x的平方和</a></p><p class="item-date"><time datetime="2019-10-21T00:00:00.000Z" itemprop="datePublished">2019/10/21</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/LeetCode/">LeetCode</a></p><p class="item-title"><a href="/2019/10/21/二分查找算法模板/" class="title">二分查找算法模板</a></p><p class="item-date"><time datetime="2019-10-21T00:00:00.000Z" itemprop="datePublished">2019/10/21</time></p></div></li></ul></div></div></div></aside><aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><nav id="toc" class="article-toc"><h3 class="toc-title">文章目录</h3><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-是什么"><span class="toc-number">1.</span> <span class="toc-text">Hadoop 是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hdfs"><span class="toc-number">2.</span> <span class="toc-text">HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-概念"><span class="toc-number">2.1.</span> <span class="toc-text">HDFS 概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据块"><span class="toc-number">2.1.1.</span> <span class="toc-text">数据块：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#对数据块进行抽象的好处"><span class="toc-number">2.1.1.1.</span> <span class="toc-text">对数据块进行抽象的好处：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#namenode"><span class="toc-number">2.1.2.</span> <span class="toc-text">NameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#联邦hdfs"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">联邦HDFS</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#datanode"><span class="toc-number">2.1.3.</span> <span class="toc-text">DataNode</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#namenode容错"><span class="toc-number">2.2.</span> <span class="toc-text">NameNode容错</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-优点"><span class="toc-number">2.3.</span> <span class="toc-text">HDFS 优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-缺点"><span class="toc-number">2.4.</span> <span class="toc-text">HDFS 缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-读写流程"><span class="toc-number">2.5.</span> <span class="toc-text">HDFS 读写流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#hdfs-读流程"><span class="toc-number">2.5.1.</span> <span class="toc-text">HDFS 读流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#客户端如何读取datanode上所存的块数据"><span class="toc-number">2.5.1.1.</span> <span class="toc-text">客户端如何读取DataNode上所存的块数据？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#读取流程的细节"><span class="toc-number">2.5.1.2.</span> <span class="toc-text">读取流程的细节：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hdfs写流程"><span class="toc-number">2.5.2.</span> <span class="toc-text">HDFS写流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#客户端如何将文件写入到datanode"><span class="toc-number">2.5.2.1.</span> <span class="toc-text">客户端如何将文件写入到DataNode？</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#当写入时有datanode发生故障导致数据无法正常写入该怎么处理"><span class="toc-number">2.5.2.1.1.</span> <span class="toc-text">当写入时有DataNode发生故障，导致数据无法正常写入，该怎么处理？？</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#hdfs如何选择副本的存储位置"><span class="toc-number">2.5.2.2.</span> <span class="toc-text">HDFS如何选择副本的存储位置？</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#参考资料"><span class="toc-number">2.5.3.</span> <span class="toc-text">参考资料</span></a></li></ol></li></ol></li></ol></nav></div></aside><main class="main" role="main"><div class="content"><article id="post-Hadoop-HDFS读写原理" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">HDFS读写原理</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/2019/08/25/Hadoop-HDFS读写原理/" class="article-date"><time datetime="2019-08-25T00:00:00.000Z" itemprop="datePublished">2019/08/25</time></a></span> <span class="article-category"><i class="icon icon-folder"></i> <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a></span> <span class="article-tag"><i class="icon icon-tags"></i> <a class="article-tag-link" href="/tags/HDFS/">HDFS</a></span> <span class="article-read hidden-xs"><i class="icon icon-eye-fill" aria-hidden="true"></i> <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span></span></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2019/08/25/Hadoop-HDFS读写原理/#comments" class="article-comment-link">评论</a></span> <span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 3.5k(字)</span> <span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 12(分)</span></div></div><div class="article-entry marked-body" itemprop="articleBody"><h2 id="hadoop-是什么"><a class="markdownIt-Anchor" href="#hadoop-是什么"></a> Hadoop 是什么</h2><blockquote><p>Hadoop 是一个开源的大数据框架同时也是一个分布式计算的解决方案。Hadoop = <strong>HDFS （分布式文件系统）+MapReduce（分布式计算）</strong></p></blockquote><h2 id="hdfs"><a class="markdownIt-Anchor" href="#hdfs"></a> HDFS</h2><h3 id="hdfs-概念"><a class="markdownIt-Anchor" href="#hdfs-概念"></a> HDFS 概念</h3><ol><li>数据块</li><li>NameNode</li><li>DataNode</li></ol><h4 id="数据块"><a class="markdownIt-Anchor" href="#数据块"></a> 数据块：</h4><p>数据块是一个抽象的块，而不是整个文件。默认大小是64Mb，一般设置为128Mb，备份x3<br>数据块的大小可以随着磁盘传输速率的提升而得到增加。</p><blockquote><p>HDFS的块比磁盘的大，主要是减少寻址时间在整个文件传输时间中的占比。比如为了让磁盘寻址时间只占到整个文件传输时间的1%，而寻址时间为10ms，磁盘的IO传输速率为100Mb/s，那么一个块的大小要大于100Mb才能达到这个要求。随着以后磁盘的传输速率越来越高，块的大小也会越来越大的。 【但是块的大小也不会很大，因为MapReduce中的map任务一次只处理一个块的数据，如果map任务过少（少于集群的节点数量），作业的运行效率也会比较慢】</p></blockquote><h5 id="对数据块进行抽象的好处"><a class="markdownIt-Anchor" href="#对数据块进行抽象的好处"></a> 对数据块进行抽象的好处：</h5><ul><li>一个文件的大小可以大于集群网络中任一个磁盘的大小。因为可以对文件进行分块存储，所以在一种极端情况下，一个集群只存放了一个文件，该文件占满了集群中的所有磁盘。</li><li>使用抽象块而不是整个文件作为存储单元，可以简化存储子系统的设计。首先块的大小是固定的，所以一个磁盘能够存储多少个块很容易就能够计算出来。另外也消除了对于元数据的顾虑，块只是要存储的大块数据，而文件的元数据，例如权限信息等等，并不需要与块进行一同存储，可以进行单独管理。</li><li>块适合于提供备份和冗余容错的作用，通过将块进行复制副本，通常是3个，当因损坏或者机器故障而丢失的块，我们便可以从其他候选机器将副本块复制到另一台能够正常工作的机器上，保证副本的数量保持不变。</li></ul><hr><blockquote><p>HDFS集群有两类节点，以管理节点-工作节点的模式运行着，分别是NameNode和DataNode。</p></blockquote><h4 id="namenode"><a class="markdownIt-Anchor" href="#namenode"></a> NameNode</h4><p>NameNode ：</p><ol><li>管理文件系统的命名空间，存放着元数据 （对应文件：<strong>命名空间镜像文件</strong>）</li><li>维护着文件系统树以及整棵树内所有的文件以及目录 （对应文件：<strong>编辑日志</strong>）</li><li>记录着每个文件各个块所在的数据节点信息，但并不会一直保存块的位置信息，因为在重启时会根据数据节点信息重建。</li></ol><h5 id="联邦hdfs"><a class="markdownIt-Anchor" href="#联邦hdfs"></a> 联邦HDFS</h5><blockquote><p>NameNode节点在内存中保存着文件系统中每个文件和每个数据块的引用关系，所以NameNode的内存大小会成为集群扩展的一个瓶颈。</p></blockquote><blockquote><p>在Hadoop 2.x版本中引入了联邦HDFS，允许在集群中添加多个NameNode节点，以实现扩展。</p></blockquote><blockquote><p>在联邦环境下，每个NameNode都维护着一个<strong>命名空间卷</strong>( 比如NameNode_1负责 /usr NameNode_2 负责 /share )，由<strong>命名空间的元数据和数据块池</strong>组成。</p><blockquote><p>数据块池里面存放着该命名空间下所有的数据块。</p></blockquote></blockquote><blockquote><p>命名空间卷之间不进行通信，甚至其中一个挂掉也不会影响另一个。但每个DataNode需要注册到每一个NameNode上，也需要存储着来自各个数据块池的数据块。</p></blockquote><h4 id="datanode"><a class="markdownIt-Anchor" href="#datanode"></a> DataNode</h4><ol><li>存储以及检索数据块</li><li>向NameNode更新所存储块的列表</li></ol><hr><h3 id="namenode容错"><a class="markdownIt-Anchor" href="#namenode容错"></a> NameNode容错</h3><blockquote><p>若NameNode失效，则我们无法访问到文件系统上的所有文件。因为我们不知道怎么去根据DataNode的块去重建文件。因此需要对NameNode进行容错处理。</p></blockquote><p><em><strong>两种容错机制：</strong></em></p><ul><li><p>对于<strong>组成文件系统元数据持久状态的文件</strong> 我们可以使NameNode在多个文件系统上对其进行保存，比如最常用的就是在将持久状态写入本地磁盘的同时也将其<strong>写入到远程挂载的NFS网络文件系统</strong>中。</p></li><li><p>运行一个<strong>辅助NameNode节点</strong> （Secondary NameNode）该节点却不能被用作NameNode，它的主要作用是<strong>定期合并编辑日志文件和命名空间镜像文件</strong>，防止其过大。它在合并后会生成命名空间镜像文件的副本，当NameNode失效时会启用。但是辅助NameNode节点保存的信息总是会滞后于NameNode节点，所以如果想要实现容错机制，可以在主NameNode节点失效后，将<strong>保存在NFS的文件系统元数据复制到Secondary NamoNode</strong>上来，将其作为新的主NameNode运行。</p></li></ul><p><em><strong>HA高可用</strong></em></p><hr><h3 id="hdfs-优点"><a class="markdownIt-Anchor" href="#hdfs-优点"></a> HDFS 优点</h3><ul><li>适合大文件存储，支持TB、PB级文件的存储</li><li>可以构建在廉价的机器上，并能够提供容错机制和恢复机制</li><li>支持流式数据访问，一次写入，多次读取更高效</li></ul><h3 id="hdfs-缺点"><a class="markdownIt-Anchor" href="#hdfs-缺点"></a> HDFS 缺点</h3><ul><li>不适合大量小文件存储</li><li>不适合并发写入，也不支持文件随机修改</li><li>不支持随机读等低延迟的访问方式</li></ul><h3 id="hdfs-读写流程"><a class="markdownIt-Anchor" href="#hdfs-读写流程"></a> HDFS 读写流程</h3><h4 id="hdfs-读流程"><a class="markdownIt-Anchor" href="#hdfs-读流程"></a> HDFS 读流程</h4><p><strong>HDFS读流程图</strong><br><img src="/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E6%85%95%E8%AF%BE%EF%BC%89.png" alt=""><br>(图片来源-慕课网)</p><blockquote><p>假设现在有三个DataNode节点，分别存放着数据Data数据块1、数据块2、数据块1、2，则如果此时客户端想要请求Data数据，流程如下：</p></blockquote><ol><li>Client向NameNode发出请求，请求Data文件。</li><li>NameNode通过其所维护的相关的数据块的信息，会把<strong>该Data文件的所有block的所有的DataNode信息</strong>返回给Client。</li><li>然后Client随即从<strong>距离</strong>(按照带宽进行计算出来的距离) 最近且保存着文件第一个块的DataNode节点上读取数据</li><li>在读取完第一个块的数据以后，便会寻找下一个块的最佳DataNode，并从其上读取数据，直到将所有的Data文件块数据读取完毕</li><li>如果在读取的过程中，遇到问题（比如读取的DataNode节点挂掉了），则客户端会再次去寻找存有该块信息副本的DataNode节点，并从其上读取出块数据。</li></ol><p><strong>如下图所示：</strong></p><p><img src="/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E5%B7%B2%E7%BB%8F%E8%AF%BB%E5%8F%96%E5%AE%8C%E6%AF%95%EF%BC%89.png" alt=""></p><blockquote><p>然而上述的流程有些地方不够完善。客户端是怎么去读取块的数据的？读过程对于客户端而言是否是透明的？依据距离去寻找最优的DataNode节点，这个距离是如何计算的？</p></blockquote><p><strong>详细的读流程图如下所示：</strong></p><p><img src="/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B%EF%BC%88%E8%AF%A6%E7%BB%86%EF%BC%89.png" alt=""></p><h5 id="客户端如何读取datanode上所存的块数据"><a class="markdownIt-Anchor" href="#客户端如何读取datanode上所存的块数据"></a> 客户端如何读取DataNode上所存的块数据？</h5><p>步骤一：客户端通过FileSyste对象的open()方法去打开希望读取的文件；</p><p>步骤二：此时，DistributedFileSystem会通过RPC去调用NameNode，然后NameNode会返回存有该文件所有block的所有的DataNode信息 （对于每一个块，NameNode会返回存有该块副本的DataNode信息，并按照距离对DataNode进行排序）；</p><p>步骤三：然后，DistributedFileSystem类会返回一个FSDataInputStream对象给客户端去读取数据</p><ul><li>该FSDataInputStream类会封装DFSInputStream对象，该对象管理着datanode和namenode的I/O</li></ul><p>步骤四：客户端对这个数据流调用read()方法去读取块数据：</p><ul><li>DFSInputStream里存放着文件前几个块的副本的所有DataNode地址，于是会去连接距离最近的DataNode</li></ul><p>步骤五：Client通过对数据流反复调用read()方法，在DFSInputStream读取完第一个块的数据以后，会关闭与该DataNode的连接，转而去连接下一个距离最近且存着第二个块数据的DataNode节点，继续读取数据。<strong>整个过程对于Client而言是完全透明的，在客户端而言，它一直在读取一个连续的数据流</strong></p><p>步骤六：Client在读取了文件前几个块的数据以后，根据需要，Client可能会询问NameNode节点检索下一批DataNode数据块的位置，然后继续通过DFSInputStream去读取数据。客户端一旦完成了数据读取，便会对FSDataInputStream调用close()方法。</p><h5 id="读取流程的细节"><a class="markdownIt-Anchor" href="#读取流程的细节"></a> 读取流程的细节：</h5><blockquote><p>在读取过程中，如果某一个DataNode发生故障，DFSInputStream会尝试连接另外一个最临近的DataNode，并记下该故障DataNode，保证后面不会再去该节点读取数据。DFSInputStream会通过<strong>校验和</strong>去检查读取的文件的正确性。</p></blockquote><blockquote><p>这种读取流程，让NameNode的工作量大大减少，只需要响应客户端的块位置请求即可，无需响应数据请求，所以可以支持高扩展。</p></blockquote><blockquote><p><strong>距离</strong>是按照带宽来进行计算的，一般来说可以依据场景，对带宽进行递减：<br>1.同一节点的不同进程<br>2.同一机架的不同节点<br>3.同一数据中心的不同机架上的节点<br>4.不同数据中心的节点</p></blockquote><h4 id="hdfs写流程"><a class="markdownIt-Anchor" href="#hdfs写流程"></a> HDFS写流程</h4><p><strong>HDFS写流程图</strong><br><img src="/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E5%86%99%E6%B5%81%E7%A8%8B.png" alt=""><br>（图片来源-慕课网）</p><ol><li>首先，客户端会向NameNode请求写入文件</li><li>NameNode通过查询自己维护的节点信息，向客户端返回还有空间可以存放数据的DataNode节点信息</li><li>客户端将data文件进行分块，然后将块内容以及NameNode发送给客户端的信息一起发送给DataNode-1</li><li>DataNode-1收到以后，会在管线中进行块数据的备份复制，使得达到块数据的最小复本数</li><li>当DataNode-1-2-3都存储完数据块以后，将会反馈给NameNode存储完成数据块-1信息，NameNode更新一下元数据信息，接着NameNode再将该信息返回给客户端</li><li>客户端再次开始存储数据块-2</li></ol><blockquote><p>然而上述的流程还不够清晰，有很多细节值得去深入了解一下。比如：<br>客户端是如何将块文件写入到DataNode中的，是以块为单位直接传输吗？<br>DataNode如何实现将数据备份到其他DataNode节点上的呢？<br>如果在写入块数据的过程中，发生了错误，HDFS会怎么处理呢？</p></blockquote><p>来自《Hadoop权威指南》的HDFS写文件流程图：<br><img src="/images/HDFS%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/HDFS%E5%86%99%E6%B5%81%E7%A8%8B%EF%BC%88%E8%AF%A6%E7%BB%86%EF%BC%89.png" alt=""></p><h5 id="客户端如何将文件写入到datanode"><a class="markdownIt-Anchor" href="#客户端如何将文件写入到datanode"></a> 客户端如何将文件写入到DataNode？</h5><blockquote><p><strong>create：</strong></p></blockquote><ul><li>客户端通过DistributedFileSystem对象调用create()方法来创建一个新文件</li><li>DistributedFileSystem的create()方法会返回一个FSDataOutputStream对象</li><li>FSDataOutputStream封装了一个DFSOutputStream对象，在其构造函数中会使用RPC远程调用NameNode的create()方法来创建一个文件</li><li>NameNode会先对文件创建操作进行检查（比如该客户端有没有权限创建文件，该文件名是否已经存在？），若检查没问题，NameNode则为创建新文件做一条记录，否则创建失败，并向客户端返回IOException异常</li></ul><blockquote><p><strong>write packet 和 ack packet：</strong></p></blockquote><blockquote><p>客户端写入数据块时，DFSOutputStream将其分成一个一个的包（packet），将packet放到pipeline（管线）里进行写入。写入时，会使用两个队列，一个是“数据队列”用于存放要写入packet；一个则是“确认队列“，用于接收DataNode发来的确认Ack。</p></blockquote><p>写入过程：（DataStreamer负责处理）</p><ul><li>一般会使用FSDataOutputStream的write方法</li><li>FSDataOutputStream的write方法会调用DFSOutputStream的write方法，而DFSOutputStream继承自FSOutputSummer，所以实际上是调用FSOutputSummer的write方法</li><li>首先将package 1写入DataNode 1然后由DataNode 1负责将package 1写入DataNode 2，同时客户端可以将pacage 2写入DataNode 1</li><li>然后DataNode 2负责将package 1写入DataNode 3, 同时客户端可以讲package 3写入DataNode 1，DataNode 1将package 2写入DataNode 2</li><li>就这样将一个个package排着队的传递下去，直到所有的数据全部写入并复制完毕</li></ul><p>确认过程：</p><ul><li>DataStreamer线程负责把准备好的数据packet，顺序写入到DataNode，未确认写入成功的packet则移动到ackQueue，等待确认。</li><li>DataStreamer线程传输数据到DataNode时，要向namenode申请数据块，在NameNode分配了DataNode和block以后，createBlockOutputStream开始写入数据。</li><li>只有对于一个数据包（packet）收到管道内的所有DataNode的ack之后，才能将该数据包从确认队列中删除。</li></ul><h6 id="当写入时有datanode发生故障导致数据无法正常写入该怎么处理"><a class="markdownIt-Anchor" href="#当写入时有datanode发生故障导致数据无法正常写入该怎么处理"></a> 当写入时有DataNode发生故障，导致数据无法正常写入，该怎么处理？？</h6><blockquote><p>DataStreamer会启动ResponseProcessor线程，它负责接收datanode的ack</p></blockquote><ul><li>首先将管线关闭</li><li>将确认队列的数据包添加回数据队列的前端</li><li>将发生故障的DataNode从管线中移除</li><li>在另一个正常的DataNode节点对当前的数据块做一个标记，并将标识发给NameNode，使损坏的DataNode恢复正常后能够删除已存储的部分数据块</li><li>通过RPC调用DataNode的recoverBlock方法来恢复数据块</li><li>以剩下的DataNode节点建立新的管线，继续写入数据（NameNode注意到块复本数量不足时，会重新添加一个DataNode进行副本数据保存）</li></ul><h5 id="hdfs如何选择副本的存储位置"><a class="markdownIt-Anchor" href="#hdfs如何选择副本的存储位置"></a> HDFS如何选择副本的存储位置？</h5><blockquote><p>副本存放位置的选定需要同时对可靠性、写入带宽和读取带宽同时均衡考量进行选取<br><strong>默认布局：</strong></p></blockquote><ul><li>第一个副本一般放在客户端，如果客户端在数据中心之外，则会随机在数据中心选择一个节点</li><li>第二个副本，选择和第一个在不同的机架的一个节点</li><li>第三个副本则选择和第二个副本在一个机架上，但是是不同的节点</li><li>后面的副本会随机选择，不过系统会尽量避免一个机架上会存放过多的副本</li></ul><h4 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h4><ul><li><p><a href="https://www.imooc.com/learn/928" rel="external nofollow noopener noreferrer" target="_blank">慕课网-Hadoop基础及演练 </a>: <a href="https://www.imooc.com/learn/928" rel="external nofollow noopener noreferrer" target="_blank">https://www.imooc.com/learn/928</a></p></li><li><p><a href="https://www.cnblogs.com/ggjucheng/archive/2013/02/19/2917020.html" rel="external nofollow noopener noreferrer" target="_blank">HDFS-dfsclient写文件过程源码分析</a>:<a href="https://www.cnblogs.com/ggjucheng/archive/2013/02/19/2917020.html" rel="external nofollow noopener noreferrer" target="_blank">https://www.cnblogs.com/ggjucheng/archive/2013/02/19/2917020.html</a></p></li><li><p>《Hadoop权威指南》</p></li></ul></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="http://81.68.66.74/2019/08/25/Hadoop-HDFS读写原理/" title="HDFS读写原理" target="_blank" rel="external">http://81.68.66.74/2019/08/25/Hadoop-HDFS读写原理/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external nofollow noopener noreferrer">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！</li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/juntao-hu" target="_blank" class="img-burn thumb-sm visible-lg" rel="external nofollow noopener noreferrer"><img src="/images/avatar.jpg" class="img-rounded w-full" alt=""></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/juntao-hu" target="_blank" rel="external nofollow noopener noreferrer"><span class="text-dark">junthy</span><small class="ml-1x">Big Data Engineer</small></a></h3><div>一个平凡人</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom=""><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/2019/08/30/浦发和美团面试总结/" title="浦发和美团面试"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a></li><li class="next"><a href="/2019/04/13/基本排序算法-Java/" title="基本排序算法（Java）"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li><li class="toggle-toc"><a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button"><span>[&nbsp;</span><span>文章目录</span> <i class="text-collapsed icon icon-anchor"></i> <i class="text-in icon icon-close"></i> <span>]</span></a></li></ul><button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone,wechat"></div></div></div></nav><div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog"><div class="modal-dialog" role="document"><div class="modal-content donate"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button><div class="modal-body"><div class="donate-box"><div class="donate-head"><p>感谢您的支持，我会继续努力的!</p></div><div class="tab-content"><div role="tabpanel" class="tab-pane fade active in" id="alipay"><div class="donate-payimg"><img src="/images/donate/alipayimg.jpg" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p></div><div role="tabpanel" class="tab-pane fade" id="wechatpay"><div class="donate-payimg"><img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p></div></div><div class="donate-footer"><ul class="nav nav-tabs nav-justified" role="tablist"><li role="presentation" class="active"><a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a></li><li role="presentation"><a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a></li></ul></div></div></div></div></div></div></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/juntao-hu" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="http://weibo.com/cofess" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"></div></footer><script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var N={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(未命名)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=N}(window)</script><script src="/js/insight.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"2KuYblUX89BF0PtLc07RGAY6-MdYXbMMI",appKey:"snKQXYKqKwE0YzkcKm1YqiM5",placeholder:"just talk it!",avatar:"mm",meta:meta,pageSize:"10",visitor:!1})</script><script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.js"></script><script>$(document).ready(function(){$("article img").not("[hidden]").not(".panel-body img").each(function(){var a=$(this),t=a.attr("alt"),n=a.parent("a");if(n.length<1){var e=this.getAttribute("src"),r=e.lastIndexOf("?");-1!=r&&(e=e.substring(0,r)),n=a.wrap('<a href="'+e+'"></a>').parent("a")}n.attr("data-fancybox","images"),t&&n.attr("data-caption",t)}),$().fancybox({selector:'[data-fancybox="images"]',hash:!1,loop:!1})})</script></body></html><!-- rebuild by neat -->